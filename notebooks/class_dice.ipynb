{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Exploring class-specific dice score calculation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-12-14 07:07:14.799136: E tensorflow/compiler/xla/stream_executor/cuda/cuda_dnn.cc:9342] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
      "2023-12-14 07:07:14.799189: E tensorflow/compiler/xla/stream_executor/cuda/cuda_fft.cc:609] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
      "2023-12-14 07:07:14.799221: E tensorflow/compiler/xla/stream_executor/cuda/cuda_blas.cc:1518] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
      "2023-12-14 07:07:14.805910: I tensorflow/core/platform/cpu_feature_guard.cc:182] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: AVX2 FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2023-12-14 07:07:16.287015: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\n"
     ]
    }
   ],
   "source": [
    "from TissueLabeling.config import Configuration\n",
    "from TissueLabeling.data.dataset import get_data_loader\n",
    "from TissueLabeling.metrics.metrics import Dice\n",
    "from TissueLabeling.models.segformer import Segformer\n",
    "from TissueLabeling.models.unet import Unet\n",
    "from TissueLabeling.models.simple_unet import SimpleUnet\n",
    "from TissueLabeling.parser import get_args\n",
    "from TissueLabeling.training.trainer import Trainer\n",
    "from TissueLabeling.utils import init_cuda, init_fabric, init_wandb, set_seed, main_timer"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "## Simple Example (test Matthias's code)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "nr_of_classes = 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([4, 4]) torch.Size([4, 4])\n"
     ]
    }
   ],
   "source": [
    "y_true = torch.Tensor([[1,1,0,0],[1,1,0,0],[1,1,1,0],[1,1,0,0]])\n",
    "pred = torch.Tensor([[1,1,1,0],[1,1,0,0],[0,0,0,0],[0,0,0,0]])\n",
    "print(y_true.shape, pred.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'y_pred' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[11], line 4\u001b[0m\n\u001b[1;32m      2\u001b[0m pred \u001b[38;5;241m=\u001b[39m pred\u001b[38;5;241m.\u001b[39mreshape((\u001b[38;5;241m1\u001b[39m,\u001b[38;5;241m1\u001b[39m,\u001b[38;5;241m4\u001b[39m,\u001b[38;5;241m4\u001b[39m))\n\u001b[1;32m      3\u001b[0m \u001b[38;5;66;03m# y_pred = torch.concat(((pred == 0).dtype(torch.float32)),axis=1)\u001b[39;00m\n\u001b[0;32m----> 4\u001b[0m \u001b[38;5;28mprint\u001b[39m(y_true\u001b[38;5;241m.\u001b[39mshape, \u001b[43my_pred\u001b[49m\u001b[38;5;241m.\u001b[39mshape)\n",
      "\u001b[0;31mNameError\u001b[0m: name 'y_pred' is not defined"
     ]
    }
   ],
   "source": [
    "y_true = y_true.reshape((1,1,4,4)).long()\n",
    "pred = pred.reshape((1,1,4,4))\n",
    "y_pred = torch.concat(((pred == 0).dtype(torch.float32)),axis=1)\n",
    "print(y_true.shape, y_pred.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_true_oh = torch.nn.functional.one_hot(\n",
    "            y_true.squeeze(1), num_classes=nr_of_classes\n",
    "        ).permute(0, 3, 1, 2)\n",
    "y_true_oh.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'y_true_oh' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[6], line 2\u001b[0m\n\u001b[1;32m      1\u001b[0m class_intersect \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39msum(\n\u001b[0;32m----> 2\u001b[0m             (\u001b[43my_true_oh\u001b[49m \u001b[38;5;241m*\u001b[39m y_pred), axis\u001b[38;5;241m=\u001b[39m(\u001b[38;5;241m2\u001b[39m, \u001b[38;5;241m3\u001b[39m)\n\u001b[1;32m      3\u001b[0m         )\n\u001b[1;32m      4\u001b[0m \u001b[38;5;28mprint\u001b[39m(class_intersect) \u001b[38;5;66;03m# expected = [6,4]\u001b[39;00m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'y_true_oh' is not defined"
     ]
    }
   ],
   "source": [
    "class_intersect = torch.sum(\n",
    "            (y_true_oh * y_pred), axis=(2, 3)\n",
    "        )\n",
    "print(class_intersect) # expected = [6,4]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[18., 14.]])\n"
     ]
    }
   ],
   "source": [
    "class_union = torch.sum(\n",
    "            (y_true_oh + y_pred), axis=(2, 3)\n",
    "        )\n",
    "print(class_union) # expected = [18,14]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[0.6667, 0.5714]])\n"
     ]
    }
   ],
   "source": [
    "class_dice = 2 * class_intersect / class_union\n",
    "print(class_dice) # expected = [0.667,0.5714]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torchmetrics\n",
    "f1 = torchmetrics.F1Score(\"multiclass\",num_classes=2,average=None)\n",
    "f1(preds,target)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Exploring outputs of test_dice.py - Binary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "nr_of_classes = 2\n"
     ]
    }
   ],
   "source": [
    "# load files\n",
    "save_path = '/om2/user/sabeen/nobrainer_data_norm/test_dice_data/binary'\n",
    "nr_of_classes = 51\n",
    "# get image/mask/probs from each multi_gp (saved as _#.pt where # = gpu global rank during multi gpu run)\n",
    "image_0,mask_0,probs_0 = torch.load(os.path.join(save_path,'image_mask_probs_0.pt'))\n",
    "image_1,mask_1,probs_1 = torch.load(os.path.join(save_path,'image_mask_probs_1.pt'))\n",
    "\n",
    "# get class_intersect/class_union\n",
    "class_intersect_0, class_union_0 = torch.load(os.path.join(save_path,f'itersect_denom_0.pt'))\n",
    "class_intersect_1, class_union_1 = torch.load(os.path.join(save_path,f'itersect_denom_1.pt'))\n",
    "\n",
    "# get gathered\n",
    "class_intersect_gather_0, class_union_gather_0 = torch.load(os.path.join(save_path,f'itersect_denom_gather_0.pt'))\n",
    "class_intersect_gather_1, class_union_gather_1 = torch.load(os.path.join(save_path,f'itersect_denom_gather_1.pt'))\n",
    "\n",
    "nr_of_classes = class_intersect_0.shape[1]\n",
    "print(f'nr_of_classes = {nr_of_classes}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Using torchmetrics F1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torchmetrics import F1Score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "f1 = F1Score(task=\"multiclass\",num_classes=2,average=None)\n",
    "# requires input to be (pred, target) where pred.shape = (num_classes,num_values) and target.shape = (num_values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "('The `preds` and `target` should have the same shape,', ' got `preds` with shape=torch.Size([1, 2, 162, 194]) and `target` with shape=torch.Size([1, 1, 162, 194]).')",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[26], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m \u001b[43mf1\u001b[49m\u001b[43m(\u001b[49m\u001b[43mprobs_0\u001b[49m\u001b[43m,\u001b[49m\u001b[43mmask_0\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/om2/user/sabeen/miniconda/lib/python3.9/site-packages/torch/nn/modules/module.py:1518\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1516\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[1;32m   1517\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 1518\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/om2/user/sabeen/miniconda/lib/python3.9/site-packages/torch/nn/modules/module.py:1527\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1522\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1523\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1524\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1525\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1526\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1527\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1529\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m   1530\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "File \u001b[0;32m/om2/user/sabeen/miniconda/lib/python3.9/site-packages/torchmetrics/metric.py:298\u001b[0m, in \u001b[0;36mMetric.forward\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m    296\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_cache \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_full_state_update(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[1;32m    297\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m--> 298\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_cache \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_forward_reduce_state_update\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    300\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_cache\n",
      "File \u001b[0;32m/om2/user/sabeen/miniconda/lib/python3.9/site-packages/torchmetrics/metric.py:367\u001b[0m, in \u001b[0;36mMetric._forward_reduce_state_update\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m    364\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_enable_grad \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mTrue\u001b[39;00m  \u001b[38;5;66;03m# allow grads for batch computation\u001b[39;00m\n\u001b[1;32m    366\u001b[0m \u001b[38;5;66;03m# calculate batch state and compute batch value\u001b[39;00m\n\u001b[0;32m--> 367\u001b[0m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mupdate\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    368\u001b[0m batch_val \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcompute()\n\u001b[1;32m    370\u001b[0m \u001b[38;5;66;03m# reduce batch and global state\u001b[39;00m\n",
      "File \u001b[0;32m/om2/user/sabeen/miniconda/lib/python3.9/site-packages/torchmetrics/metric.py:457\u001b[0m, in \u001b[0;36mMetric._wrap_update.<locals>.wrapped_func\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    455\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m torch\u001b[38;5;241m.\u001b[39mset_grad_enabled(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_enable_grad):\n\u001b[1;32m    456\u001b[0m     \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m--> 457\u001b[0m         \u001b[43mupdate\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    458\u001b[0m     \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mRuntimeError\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m err:\n\u001b[1;32m    459\u001b[0m         \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mExpected all tensors to be on\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mstr\u001b[39m(err):\n",
      "File \u001b[0;32m/om2/user/sabeen/miniconda/lib/python3.9/site-packages/torchmetrics/classification/stat_scores.py:322\u001b[0m, in \u001b[0;36mMulticlassStatScores.update\u001b[0;34m(self, preds, target)\u001b[0m\n\u001b[1;32m    320\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124;03m\"\"\"Update state with predictions and targets.\"\"\"\u001b[39;00m\n\u001b[1;32m    321\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mvalidate_args:\n\u001b[0;32m--> 322\u001b[0m     \u001b[43m_multiclass_stat_scores_tensor_validation\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    323\u001b[0m \u001b[43m        \u001b[49m\u001b[43mpreds\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtarget\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mnum_classes\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmultidim_average\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mignore_index\u001b[49m\n\u001b[1;32m    324\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    325\u001b[0m preds, target \u001b[38;5;241m=\u001b[39m _multiclass_stat_scores_format(preds, target, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtop_k)\n\u001b[1;32m    326\u001b[0m tp, fp, tn, fn \u001b[38;5;241m=\u001b[39m _multiclass_stat_scores_update(\n\u001b[1;32m    327\u001b[0m     preds, target, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mnum_classes, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtop_k, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39maverage, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mmultidim_average, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mignore_index\n\u001b[1;32m    328\u001b[0m )\n",
      "File \u001b[0;32m/om2/user/sabeen/miniconda/lib/python3.9/site-packages/torchmetrics/functional/classification/stat_scores.py:292\u001b[0m, in \u001b[0;36m_multiclass_stat_scores_tensor_validation\u001b[0;34m(preds, target, num_classes, multidim_average, ignore_index)\u001b[0m\n\u001b[1;32m    290\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m preds\u001b[38;5;241m.\u001b[39mndim \u001b[38;5;241m==\u001b[39m target\u001b[38;5;241m.\u001b[39mndim:\n\u001b[1;32m    291\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m preds\u001b[38;5;241m.\u001b[39mshape \u001b[38;5;241m!=\u001b[39m target\u001b[38;5;241m.\u001b[39mshape:\n\u001b[0;32m--> 292\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[1;32m    293\u001b[0m             \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mThe `preds` and `target` should have the same shape,\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m    294\u001b[0m             \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m got `preds` with shape=\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mpreds\u001b[38;5;241m.\u001b[39mshape\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m and `target` with shape=\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mtarget\u001b[38;5;241m.\u001b[39mshape\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m.\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m    295\u001b[0m         )\n\u001b[1;32m    296\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m multidim_average \u001b[38;5;241m!=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mglobal\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;129;01mand\u001b[39;00m preds\u001b[38;5;241m.\u001b[39mndim \u001b[38;5;241m<\u001b[39m \u001b[38;5;241m2\u001b[39m:\n\u001b[1;32m    297\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[1;32m    298\u001b[0m             \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mWhen `preds` and `target` have the same shape, the shape of `preds` should \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    299\u001b[0m             \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m atleast 2D when multidim_average is set to `samplewise`\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    300\u001b[0m         )\n",
      "\u001b[0;31mValueError\u001b[0m: ('The `preds` and `target` should have the same shape,', ' got `preds` with shape=torch.Size([1, 2, 162, 194]) and `target` with shape=torch.Size([1, 1, 162, 194]).')"
     ]
    }
   ],
   "source": [
    "f1(probs_0,mask_0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "('The `preds` and `target` should have the same shape,', ' got `preds` with shape=torch.Size([2, 162, 194, 1]) and `target` with shape=torch.Size([1, 162, 194, 1]).')",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[31], line 3\u001b[0m\n\u001b[1;32m      1\u001b[0m preds_2 \u001b[38;5;241m=\u001b[39m probs_0\u001b[38;5;241m.\u001b[39mpermute(\u001b[38;5;241m1\u001b[39m,\u001b[38;5;241m2\u001b[39m,\u001b[38;5;241m3\u001b[39m,\u001b[38;5;241m0\u001b[39m)\n\u001b[1;32m      2\u001b[0m target_2 \u001b[38;5;241m=\u001b[39m mask_0\u001b[38;5;241m.\u001b[39mpermute(\u001b[38;5;241m1\u001b[39m,\u001b[38;5;241m2\u001b[39m,\u001b[38;5;241m3\u001b[39m,\u001b[38;5;241m0\u001b[39m)\n\u001b[0;32m----> 3\u001b[0m \u001b[43mf1\u001b[49m\u001b[43m(\u001b[49m\u001b[43mpreds_2\u001b[49m\u001b[43m,\u001b[49m\u001b[43mtarget_2\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/om2/user/sabeen/miniconda/lib/python3.9/site-packages/torch/nn/modules/module.py:1518\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1516\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[1;32m   1517\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 1518\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/om2/user/sabeen/miniconda/lib/python3.9/site-packages/torch/nn/modules/module.py:1527\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1522\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1523\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1524\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1525\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1526\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1527\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1529\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m   1530\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "File \u001b[0;32m/om2/user/sabeen/miniconda/lib/python3.9/site-packages/torchmetrics/metric.py:298\u001b[0m, in \u001b[0;36mMetric.forward\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m    296\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_cache \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_full_state_update(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[1;32m    297\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m--> 298\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_cache \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_forward_reduce_state_update\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    300\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_cache\n",
      "File \u001b[0;32m/om2/user/sabeen/miniconda/lib/python3.9/site-packages/torchmetrics/metric.py:367\u001b[0m, in \u001b[0;36mMetric._forward_reduce_state_update\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m    364\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_enable_grad \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mTrue\u001b[39;00m  \u001b[38;5;66;03m# allow grads for batch computation\u001b[39;00m\n\u001b[1;32m    366\u001b[0m \u001b[38;5;66;03m# calculate batch state and compute batch value\u001b[39;00m\n\u001b[0;32m--> 367\u001b[0m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mupdate\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    368\u001b[0m batch_val \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcompute()\n\u001b[1;32m    370\u001b[0m \u001b[38;5;66;03m# reduce batch and global state\u001b[39;00m\n",
      "File \u001b[0;32m/om2/user/sabeen/miniconda/lib/python3.9/site-packages/torchmetrics/metric.py:457\u001b[0m, in \u001b[0;36mMetric._wrap_update.<locals>.wrapped_func\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    455\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m torch\u001b[38;5;241m.\u001b[39mset_grad_enabled(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_enable_grad):\n\u001b[1;32m    456\u001b[0m     \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m--> 457\u001b[0m         \u001b[43mupdate\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    458\u001b[0m     \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mRuntimeError\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m err:\n\u001b[1;32m    459\u001b[0m         \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mExpected all tensors to be on\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mstr\u001b[39m(err):\n",
      "File \u001b[0;32m/om2/user/sabeen/miniconda/lib/python3.9/site-packages/torchmetrics/classification/stat_scores.py:322\u001b[0m, in \u001b[0;36mMulticlassStatScores.update\u001b[0;34m(self, preds, target)\u001b[0m\n\u001b[1;32m    320\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124;03m\"\"\"Update state with predictions and targets.\"\"\"\u001b[39;00m\n\u001b[1;32m    321\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mvalidate_args:\n\u001b[0;32m--> 322\u001b[0m     \u001b[43m_multiclass_stat_scores_tensor_validation\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    323\u001b[0m \u001b[43m        \u001b[49m\u001b[43mpreds\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtarget\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mnum_classes\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmultidim_average\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mignore_index\u001b[49m\n\u001b[1;32m    324\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    325\u001b[0m preds, target \u001b[38;5;241m=\u001b[39m _multiclass_stat_scores_format(preds, target, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtop_k)\n\u001b[1;32m    326\u001b[0m tp, fp, tn, fn \u001b[38;5;241m=\u001b[39m _multiclass_stat_scores_update(\n\u001b[1;32m    327\u001b[0m     preds, target, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mnum_classes, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtop_k, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39maverage, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mmultidim_average, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mignore_index\n\u001b[1;32m    328\u001b[0m )\n",
      "File \u001b[0;32m/om2/user/sabeen/miniconda/lib/python3.9/site-packages/torchmetrics/functional/classification/stat_scores.py:292\u001b[0m, in \u001b[0;36m_multiclass_stat_scores_tensor_validation\u001b[0;34m(preds, target, num_classes, multidim_average, ignore_index)\u001b[0m\n\u001b[1;32m    290\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m preds\u001b[38;5;241m.\u001b[39mndim \u001b[38;5;241m==\u001b[39m target\u001b[38;5;241m.\u001b[39mndim:\n\u001b[1;32m    291\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m preds\u001b[38;5;241m.\u001b[39mshape \u001b[38;5;241m!=\u001b[39m target\u001b[38;5;241m.\u001b[39mshape:\n\u001b[0;32m--> 292\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[1;32m    293\u001b[0m             \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mThe `preds` and `target` should have the same shape,\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m    294\u001b[0m             \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m got `preds` with shape=\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mpreds\u001b[38;5;241m.\u001b[39mshape\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m and `target` with shape=\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mtarget\u001b[38;5;241m.\u001b[39mshape\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m.\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m    295\u001b[0m         )\n\u001b[1;32m    296\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m multidim_average \u001b[38;5;241m!=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mglobal\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;129;01mand\u001b[39;00m preds\u001b[38;5;241m.\u001b[39mndim \u001b[38;5;241m<\u001b[39m \u001b[38;5;241m2\u001b[39m:\n\u001b[1;32m    297\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[1;32m    298\u001b[0m             \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mWhen `preds` and `target` have the same shape, the shape of `preds` should \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    299\u001b[0m             \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m atleast 2D when multidim_average is set to `samplewise`\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    300\u001b[0m         )\n",
      "\u001b[0;31mValueError\u001b[0m: ('The `preds` and `target` should have the same shape,', ' got `preds` with shape=torch.Size([2, 162, 194, 1]) and `target` with shape=torch.Size([1, 162, 194, 1]).')"
     ]
    }
   ],
   "source": [
    "preds_2 = probs_0.permute(1,2,3,0)\n",
    "target_2 = mask_0.permute(1,2,3,0)\n",
    "f1(preds_2,target_2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([0.3771, 0.1108])"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "preds = probs_0.reshape(2,-1).T # to reshape into (C,N) (doesn't account for batch_size)\n",
    "target = mask_0.reshape(-1) # to reshape into (N)(doesn't account for batch_size)\n",
    "f1(preds,target)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[0.6110, 0.1137]], grad_fn=<DivBackward0>)"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "2 * class_intersect_0 / class_union_0"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "### Comparison v1 - Binary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [],
   "source": [
    "# find class_intersect and class_union for batch_size = 2, single gpu case\n",
    "image = torch.concat((image_0,image_1),axis=0)\n",
    "mask = torch.concat((mask_0,mask_1),axis=0)\n",
    "probs = torch.concat((probs_0,probs_1),axis=0)\n",
    "\n",
    "# calculate intersect and union\n",
    "y_true_oh = torch.nn.functional.one_hot(\n",
    "    mask.long().squeeze(1), num_classes=nr_of_classes\n",
    ").permute(0, 3, 1, 2)\n",
    "class_intersect = torch.sum(\n",
    "    (y_true_oh * probs), axis=(2, 3)\n",
    "    )\n",
    "class_union = torch.sum(\n",
    "    (y_true_oh + probs), axis=(2, 3)\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [],
   "source": [
    "# calculate class totals\n",
    "single_intersect_sum = torch.sum(class_intersect,axis=0)\n",
    "single_denom_sum = torch.sum(class_union,axis=0)\n",
    "\n",
    "multi_intersect_sum = torch.sum(torch.concat((class_intersect_0,class_intersect_1)).reshape((2,1,nr_of_classes)),axis=0)\n",
    "multi_denom_sum = torch.sum(torch.concat((class_union_0,class_union_1)).reshape((2,1,nr_of_classes)),axis=0)\n",
    "\n",
    "gather_intersect_sum_0 = torch.sum(class_intersect_gather_0,axis=0)\n",
    "gather_denom_sum_0 = torch.sum(class_union_gather_0,axis=0)\n",
    "\n",
    "gather_intersect_sum_1 = torch.sum(class_intersect_gather_1,axis=0)\n",
    "gather_denom_sum_1 = torch.sum(class_union_gather_1,axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "sanity_check: gather_0 should equal gather_1\n",
      "gather_intersect_sum_0 == gather_intersect_sum_1: 2 / 2 are equal\n",
      "gather_denom_sum_0 == gather_denom_sum_1: 2 / 2 are equal\n",
      "\n",
      "sanity_check: multi should equal gather_0 and gather_1\n",
      "multi_intersect_sum == gather_intersect_sum_0: 2 / 2 are equal\n",
      "multi_denom_sum == gather_denom_sum_0: 2 / 2 are equal\n",
      "\n",
      "Q: does single = gather?\n",
      "single_intersect_sum == gather_intersect_sum_0: 1 / 2 are equal\n",
      "single_denom_sum == gather_denom_sum_0: 2 / 2 are equal\n",
      "\n",
      "Q: does single = multi?\n",
      "single_intersect_sum == multi_intersect_sum: 1 / 2 are equal\n",
      "single_denom_sum == multi_denom_sum: 2 / 2 are equal\n"
     ]
    }
   ],
   "source": [
    "# comparing single_gpu and multi_gpu\n",
    "print('sanity_check: gather_0 should equal gather_1')\n",
    "nr_of_classes = len(single_intersect_sum)\n",
    "print(f'gather_intersect_sum_0 == gather_intersect_sum_1: {torch.sum(gather_intersect_sum_0 == gather_intersect_sum_1)} / {nr_of_classes} are equal')\n",
    "print(f'gather_denom_sum_0 == gather_denom_sum_1: {torch.sum(gather_denom_sum_0 == gather_denom_sum_1)} / {nr_of_classes} are equal')\n",
    "print()\n",
    "\n",
    "print('sanity_check: multi should equal gather_0 and gather_1')\n",
    "print(f'multi_intersect_sum == gather_intersect_sum_0: {torch.sum(multi_intersect_sum == gather_intersect_sum_0)} / {nr_of_classes} are equal')\n",
    "print(f'multi_denom_sum == gather_denom_sum_0: {torch.sum(multi_denom_sum == gather_denom_sum_0)} / {nr_of_classes} are equal')\n",
    "print()\n",
    "\n",
    "print('Q: does single = gather?')\n",
    "print(f'single_intersect_sum == gather_intersect_sum_0: {torch.sum(gather_intersect_sum_0 == single_intersect_sum)} / {nr_of_classes} are equal')\n",
    "print(f'single_denom_sum == gather_denom_sum_0: {torch.sum(gather_denom_sum_0 == single_denom_sum)} / {nr_of_classes} are equal')\n",
    "print()\n",
    "\n",
    "print('Q: does single = multi?')\n",
    "print(f'single_intersect_sum == multi_intersect_sum: {torch.sum(multi_intersect_sum == single_intersect_sum)} / {nr_of_classes} are equal')\n",
    "print(f'single_denom_sum == multi_denom_sum: {torch.sum(multi_denom_sum == single_denom_sum)} / {nr_of_classes} are equal')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "### Comparison v2 - Binary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(0)"
      ]
     },
     "execution_count": 84,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.sum(torch.concat((class_intersect_0,class_intersect_1)).reshape((2,1,nr_of_classes)) != class_intersect_gather_0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [],
   "source": [
    "# find class_intersect and class_union for batch_size = 2, single gpu case\n",
    "image = torch.concat((image_0,image_1),axis=0)\n",
    "mask = torch.concat((mask_0,mask_1),axis=0)\n",
    "probs = torch.concat((probs_0,probs_1),axis=0)\n",
    "\n",
    "# calculate intersect and union\n",
    "y_true_oh = torch.nn.functional.one_hot(\n",
    "    mask.long().squeeze(1), num_classes=nr_of_classes\n",
    ").permute(0, 3, 1, 2)\n",
    "class_intersect = torch.sum(\n",
    "    (y_true_oh * probs), axis=(2, 3)\n",
    "    )\n",
    "class_union = torch.sum(\n",
    "    (y_true_oh + probs), axis=(2, 3)\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[[13343.8438,  1089.5955]],\n",
       "\n",
       "        [[13318.8857,  1417.1342]]], grad_fn=<ViewBackward0>)"
      ]
     },
     "execution_count": 98,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "class_intersect.reshape((2,1,nr_of_classes))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[[ 0.0000,  0.0000]],\n",
       "\n",
       "        [[-0.0010, -0.0001]]], grad_fn=<SubBackward0>)"
      ]
     },
     "execution_count": 100,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "class_intersect_gather_0 - class_intersect.reshape((2,1,nr_of_classes))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(2)"
      ]
     },
     "execution_count": 90,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.sum(class_intersect.reshape((2,1,nr_of_classes)) != class_intersect_gather_0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([1, 2, 162, 194]) torch.Size([1, 2]) torch.Size([1, 2])\n"
     ]
    }
   ],
   "source": [
    "y_true_oh_single_0 = torch.nn.functional.one_hot(\n",
    "    mask_0.long().squeeze(1), num_classes=nr_of_classes\n",
    ").permute(0, 3, 1, 2)\n",
    "class_intersect_single_0 = torch.sum(\n",
    "    (y_true_oh_single_0 * probs_0), axis=(2, 3)\n",
    ")\n",
    "class_union_single_0 = torch.sum(\n",
    "    (y_true_oh_single_0 + probs_0), axis=(2,3)\n",
    ")\n",
    "print(y_true_oh_single_0.shape, class_intersect_single_0.shape, class_union_single_0.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([1, 2, 162, 194]) torch.Size([1, 2]) torch.Size([1, 2])\n"
     ]
    }
   ],
   "source": [
    "y_true_oh_single_1 = torch.nn.functional.one_hot(\n",
    "    mask_1.long().squeeze(1), num_classes=nr_of_classes\n",
    ").permute(0, 3, 1, 2)\n",
    "class_intersect_single_1 = torch.sum(\n",
    "    (y_true_oh_single_1 * probs_1), axis=(2, 3)\n",
    ")\n",
    "class_union_single_1 = torch.sum(\n",
    "    (y_true_oh_single_1 + probs_1), axis=(2,3)\n",
    ")\n",
    "print(y_true_oh_single_1.shape, class_intersect_single_1.shape, class_union_single_1.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([2, 1, 2])"
      ]
     },
     "execution_count": 104,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a = torch.concat((class_intersect_0,class_intersect_1)).reshape((2,1,nr_of_classes))\n",
    "a.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([2, 1, 2])"
      ]
     },
     "execution_count": 106,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "b = torch.concat((class_intersect_single_0, class_intersect_single_1)).reshape((2,1,nr_of_classes))\n",
    "b.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(1)"
      ]
     },
     "execution_count": 107,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a_sum = torch.sum(a,axis=0)\n",
    "b_sum = torch.sum(b,axis=0)\n",
    "torch.sum(a_sum != b_sum)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[-0.0020,  0.0000]], grad_fn=<SubBackward0>)"
      ]
     },
     "execution_count": 108,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a_sum - b_sum"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "## Exploring outputs of test_dice.py - 51 Classes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "nr_of_classes = 51\n"
     ]
    }
   ],
   "source": [
    "# load files\n",
    "save_path = '/om2/user/sabeen/nobrainer_data_norm/test_dice_data/51class'\n",
    "nr_of_classes = 51\n",
    "# get image/mask/probs from each multi_gp (saved as _#.pt where # = gpu global rank during multi gpu run)\n",
    "image_0,mask_0,probs_0 = torch.load(os.path.join(save_path,'image_mask_probs_0.pt'))\n",
    "image_1,mask_1,probs_1 = torch.load(os.path.join(save_path,'image_mask_probs_1.pt'))\n",
    "\n",
    "# get class_intersect/class_union\n",
    "class_intersect_0, class_union_0 = torch.load(os.path.join(save_path,f'itersect_denom_0.pt'))\n",
    "class_intersect_1, class_union_1 = torch.load(os.path.join(save_path,f'itersect_denom_1.pt'))\n",
    "\n",
    "# get gathered\n",
    "class_intersect_gather_0, class_union_gather_0 = torch.load(os.path.join(save_path,f'itersect_denom_gather_0.pt'))\n",
    "class_intersect_gather_1, class_union_gather_1 = torch.load(os.path.join(save_path,f'itersect_denom_gather_1.pt'))\n",
    "\n",
    "nr_of_classes = class_intersect_0.shape[1]\n",
    "print(f'nr_of_classes = {nr_of_classes}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Comparison v1 - 51 clas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {},
   "outputs": [],
   "source": [
    "# find class_intersect and class_union for batch_size = 2, single gpu case\n",
    "image = torch.concat((image_0,image_1),axis=0)\n",
    "mask = torch.concat((mask_0,mask_1),axis=0)\n",
    "probs = torch.concat((probs_0,probs_1),axis=0)\n",
    "\n",
    "# calculate intersect and union\n",
    "y_true_oh = torch.nn.functional.one_hot(\n",
    "    mask.long().squeeze(1), num_classes=nr_of_classes\n",
    ").permute(0, 3, 1, 2)\n",
    "class_intersect = torch.sum(\n",
    "    (y_true_oh * probs), axis=(2, 3)\n",
    "    )\n",
    "class_union = torch.sum(\n",
    "    (y_true_oh + probs), axis=(2, 3)\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {},
   "outputs": [],
   "source": [
    "# calculate class totals\n",
    "single_intersect_sum = torch.sum(class_intersect,axis=0)\n",
    "single_denom_sum = torch.sum(class_union,axis=0)\n",
    "\n",
    "multi_intersect_sum = torch.sum(torch.concat((class_intersect_0,class_intersect_1)).reshape((2,1,nr_of_classes)),axis=0)\n",
    "multi_denom_sum = torch.sum(torch.concat((class_union_0,class_union_1)).reshape((2,1,nr_of_classes)),axis=0)\n",
    "\n",
    "gather_intersect_sum_0 = torch.sum(class_intersect_gather_0,axis=0)\n",
    "gather_denom_sum_0 = torch.sum(class_union_gather_0,axis=0)\n",
    "\n",
    "gather_intersect_sum_1 = torch.sum(class_intersect_gather_1,axis=0)\n",
    "gather_denom_sum_1 = torch.sum(class_union_gather_1,axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "sanity_check: gather_0 should equal gather_1\n",
      "gather_intersect_sum_0 == gather_intersect_sum_1: 51 / 51 are equal\n",
      "gather_denom_sum_0 == gather_denom_sum_1: 51 / 51 are equal\n",
      "\n",
      "sanity_check: multi should equal gather_0 and gather_1\n",
      "multi_intersect_sum == gather_intersect_sum_0: 51 / 51 are equal\n",
      "multi_denom_sum == gather_denom_sum_0: 51 / 51 are equal\n",
      "\n",
      "Q: does single = gather?\n",
      "single_intersect_sum == gather_intersect_sum_0: 49 / 51 are equal\n",
      "single_denom_sum == gather_denom_sum_0: 33 / 51 are equal\n",
      "\n",
      "Q: does single = multi?\n",
      "single_intersect_sum == multi_intersect_sum: 49 / 51 are equal\n",
      "single_denom_sum == multi_denom_sum: 33 / 51 are equal\n"
     ]
    }
   ],
   "source": [
    "# comparing single_gpu and multi_gpu\n",
    "print('sanity_check: gather_0 should equal gather_1')\n",
    "nr_of_classes = len(single_intersect_sum)\n",
    "print(f'gather_intersect_sum_0 == gather_intersect_sum_1: {torch.sum(gather_intersect_sum_0 == gather_intersect_sum_1)} / {nr_of_classes} are equal')\n",
    "print(f'gather_denom_sum_0 == gather_denom_sum_1: {torch.sum(gather_denom_sum_0 == gather_denom_sum_1)} / {nr_of_classes} are equal')\n",
    "print()\n",
    "\n",
    "print('sanity_check: multi should equal gather_0 and gather_1')\n",
    "print(f'multi_intersect_sum == gather_intersect_sum_0: {torch.sum(multi_intersect_sum == gather_intersect_sum_0)} / {nr_of_classes} are equal')\n",
    "print(f'multi_denom_sum == gather_denom_sum_0: {torch.sum(multi_denom_sum == gather_denom_sum_0)} / {nr_of_classes} are equal')\n",
    "print()\n",
    "\n",
    "print('Q: does single = gather?')\n",
    "print(f'single_intersect_sum == gather_intersect_sum_0: {torch.sum(gather_intersect_sum_0 == single_intersect_sum)} / {nr_of_classes} are equal')\n",
    "print(f'single_denom_sum == gather_denom_sum_0: {torch.sum(gather_denom_sum_0 == single_denom_sum)} / {nr_of_classes} are equal')\n",
    "print()\n",
    "\n",
    "print('Q: does single = multi?')\n",
    "print(f'single_intersect_sum == multi_intersect_sum: {torch.sum(multi_intersect_sum == single_intersect_sum)} / {nr_of_classes} are equal')\n",
    "print(f'single_denom_sum == multi_denom_sum: {torch.sum(multi_denom_sum == single_denom_sum)} / {nr_of_classes} are equal')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Comparison v2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(0)"
      ]
     },
     "execution_count": 113,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.sum(torch.concat((class_intersect_0,class_intersect_1)).reshape((2,1,nr_of_classes)) != class_intersect_gather_0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "metadata": {},
   "outputs": [],
   "source": [
    "# find class_intersect and class_union for batch_size = 2, single gpu case\n",
    "image = torch.concat((image_0,image_1),axis=0)\n",
    "mask = torch.concat((mask_0,mask_1),axis=0)\n",
    "probs = torch.concat((probs_0,probs_1),axis=0)\n",
    "\n",
    "# calculate intersect and union\n",
    "y_true_oh = torch.nn.functional.one_hot(\n",
    "    mask.long().squeeze(1), num_classes=nr_of_classes\n",
    ").permute(0, 3, 1, 2)\n",
    "class_intersect = torch.sum(\n",
    "    (y_true_oh * probs), axis=(2, 3)\n",
    "    )\n",
    "class_union = torch.sum(\n",
    "    (y_true_oh + probs), axis=(2, 3)\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(2)"
      ]
     },
     "execution_count": 119,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.sum(class_intersect.reshape((2,1,nr_of_classes)) != class_intersect_gather_0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([1, 51, 162, 194]) torch.Size([1, 51]) torch.Size([1, 51])\n"
     ]
    }
   ],
   "source": [
    "y_true_oh_single_0 = torch.nn.functional.one_hot(\n",
    "    mask_0.long().squeeze(1), num_classes=nr_of_classes\n",
    ").permute(0, 3, 1, 2)\n",
    "class_intersect_single_0 = torch.sum(\n",
    "    (y_true_oh_single_0 * probs_0), axis=(2, 3)\n",
    ")\n",
    "class_union_single_0 = torch.sum(\n",
    "    (y_true_oh_single_0 + probs_0), axis=(2,3)\n",
    ")\n",
    "print(y_true_oh_single_0.shape, class_intersect_single_0.shape, class_union_single_0.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([1, 51, 162, 194]) torch.Size([1, 51]) torch.Size([1, 51])\n"
     ]
    }
   ],
   "source": [
    "y_true_oh_single_1 = torch.nn.functional.one_hot(\n",
    "    mask_1.long().squeeze(1), num_classes=nr_of_classes\n",
    ").permute(0, 3, 1, 2)\n",
    "class_intersect_single_1 = torch.sum(\n",
    "    (y_true_oh_single_1 * probs_1), axis=(2, 3)\n",
    ")\n",
    "class_union_single_1 = torch.sum(\n",
    "    (y_true_oh_single_1 + probs_1), axis=(2,3)\n",
    ")\n",
    "print(y_true_oh_single_1.shape, class_intersect_single_1.shape, class_union_single_1.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([2, 1, 51])"
      ]
     },
     "execution_count": 122,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a = torch.concat((class_intersect_0,class_intersect_1)).reshape((2,1,nr_of_classes))\n",
    "a.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([2, 1, 51])"
      ]
     },
     "execution_count": 123,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "b = torch.concat((class_intersect_single_0, class_intersect_single_1)).reshape((2,1,nr_of_classes))\n",
    "b.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(2)"
      ]
     },
     "execution_count": 124,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a_sum = torch.sum(a,axis=0)\n",
    "b_sum = torch.sum(b,axis=0)\n",
    "torch.sum(a_sum != b_sum)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[1.2207e-04, 1.5259e-05, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n",
       "         0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n",
       "         0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n",
       "         0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n",
       "         0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n",
       "         0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n",
       "         0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n",
       "         0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n",
       "         0.0000e+00, 0.0000e+00, 0.0000e+00]], grad_fn=<SubBackward0>)"
      ]
     },
     "execution_count": 125,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a_sum - b_sum"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[-1.2207e-04, -1.5259e-05,  0.0000e+00,  0.0000e+00,  0.0000e+00,\n",
       "          0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,\n",
       "          0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,\n",
       "          0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,\n",
       "          0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,\n",
       "          0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,\n",
       "          0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,\n",
       "          0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,\n",
       "          0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,\n",
       "          0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,\n",
       "          0.0000e+00]], grad_fn=<SubBackward0>)"
      ]
     },
     "execution_count": 129,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "single_intersect_sum - gather_intersect_sum_0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[ 0.0000,  0.0000,  0.0001,  0.0000,  0.0000,  0.0001,  0.0000,  0.0000,\n",
       "          0.0000,  0.0000,  0.0000,  0.0000, -0.0001, -0.0002,  0.0000,  0.0000,\n",
       "          0.0000, -0.0001,  0.0000, -0.0001, -0.0001,  0.0000,  0.0001, -0.0002,\n",
       "          0.0000,  0.0000,  0.0000,  0.0001,  0.0000,  0.0001,  0.0000,  0.0000,\n",
       "          0.0000,  0.0000,  0.0000, -0.0001, -0.0001,  0.0000,  0.0000,  0.0000,\n",
       "          0.0000,  0.0000, -0.0001,  0.0000,  0.0000, -0.0001,  0.0000, -0.0001,\n",
       "         -0.0001,  0.0001,  0.0000]], grad_fn=<SubBackward0>)"
      ]
     },
     "execution_count": 130,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "single_denom_sum - gather_denom_sum_0"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
