{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Exploring class-specific dice score calculation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-12-13 08:59:05.644129: E tensorflow/compiler/xla/stream_executor/cuda/cuda_dnn.cc:9342] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
      "2023-12-13 08:59:05.644191: E tensorflow/compiler/xla/stream_executor/cuda/cuda_fft.cc:609] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
      "2023-12-13 08:59:05.651740: E tensorflow/compiler/xla/stream_executor/cuda/cuda_blas.cc:1518] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
      "2023-12-13 08:59:06.136033: I tensorflow/core/platform/cpu_feature_guard.cc:182] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: AVX2 FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2023-12-13 08:59:08.383605: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\n"
     ]
    }
   ],
   "source": [
    "from TissueLabeling.config import Configuration\n",
    "from TissueLabeling.data.dataset import get_data_loader\n",
    "from TissueLabeling.metrics.metrics import Dice\n",
    "from TissueLabeling.models.segformer import Segformer\n",
    "from TissueLabeling.models.unet import Unet\n",
    "from TissueLabeling.models.simple_unet import SimpleUnet\n",
    "from TissueLabeling.parser import get_args\n",
    "from TissueLabeling.training.trainer import Trainer\n",
    "from TissueLabeling.utils import init_cuda, init_fabric, init_wandb, set_seed, main_timer"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "## Simple Example (test Matthias's code)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [],
   "source": [
    "nr_of_classes = 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_true = torch.Tensor([[1,1,0,0],[1,1,0,0],[1,1,1,0],[1,1,0,0]])\n",
    "pred = torch.Tensor([[1,1,1,0],[1,1,0,0],[0,0,0,0],[0,0,0,0]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([1, 1, 4, 4]) torch.Size([1, 2, 4, 4])\n"
     ]
    }
   ],
   "source": [
    "y_true = ground_truth.reshape((1,1,4,4)).long()\n",
    "pred = pred.reshape((1,1,4,4))\n",
    "y_pred = torch.concat(((pred == 0).type(torch.float32)),axis=1)\n",
    "print(y_true.shape, y_pred.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([1, 2, 4, 4])"
      ]
     },
     "execution_count": 75,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_true_oh = torch.nn.functional.one_hot(\n",
    "            y_true.squeeze(1), num_classes=nr_of_classes\n",
    "        ).permute(0, 3, 1, 2)\n",
    "y_true_oh.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[6., 4.]])\n"
     ]
    }
   ],
   "source": [
    "class_intersect = torch.sum(\n",
    "            (y_true_oh * y_pred), axis=(2, 3)\n",
    "        )\n",
    "print(class_intersect) # expected = [6,4]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[18., 14.]])\n"
     ]
    }
   ],
   "source": [
    "class_denom = torch.sum(\n",
    "            (y_true_oh + y_pred), axis=(2, 3)\n",
    "        )\n",
    "print(class_denom) # expected = [18,14]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[0.6667, 0.5714]])\n"
     ]
    }
   ],
   "source": [
    "class_dice = 2 * class_intersect / class_denom\n",
    "print(class_dice) # expected = [0.667,0.5714]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Exploring outputs of test_dice.py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "nr_of_classes = 51\n"
     ]
    }
   ],
   "source": [
    "# load files\n",
    "save_path = '/om2/user/sabeen/nobrainer_data_norm/test_dice_data/'\n",
    "nr_of_classes = 51\n",
    "# get image/mask/probs from each multi_gp (saved as _#.pt where # = gpu global rank during multi gpu run)\n",
    "image_0,mask_0,probs_0 = torch.load(os.path.join(save_path,'image_mask_probs_0.pt'))\n",
    "image_1,mask_1,probs_1 = torch.load(os.path.join(save_path,'image_mask_probs_1.pt'))\n",
    "\n",
    "# get class_intersect/class_denom\n",
    "class_intersect_0, class_denom_0 = torch.load(os.path.join(save_path,f'itersect_denom_0.pt'))\n",
    "class_intersect_1, class_denom_1 = torch.load(os.path.join(save_path,f'itersect_denom_1.pt'))\n",
    "\n",
    "# get gathered\n",
    "class_intersect_gather_0, class_denom_gather_0 = torch.load(os.path.join(save_path,f'itersect_denom_gather_0.pt'))\n",
    "class_intersect_gather_1, class_denom_gather_1 = torch.load(os.path.join(save_path,f'itersect_denom_gather_1.pt'))\n",
    "\n",
    "nr_of_classes = class_intersect_0.shape[1]\n",
    "print(f'nr_of_classes = {nr_of_classes}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# find class_intersect and class_denom for batch_size = 2, single gpu case\n",
    "image = torch.concat((image_0,image_1),axis=0)\n",
    "mask = torch.concat((mask_0,mask_1),axis=0)\n",
    "probs = torch.concat((probs_0,probs_1),axis=0)\n",
    "\n",
    "# calculate intersect and union\n",
    "y_true_oh = torch.nn.functional.one_hot(\n",
    "    mask.long().squeeze(1), num_classes=nr_of_classes\n",
    ").permute(0, 3, 1, 2)\n",
    "class_intersect = torch.sum(\n",
    "    (y_true_oh * probs), axis=(2, 3)\n",
    "    )\n",
    "class_denom = torch.sum(\n",
    "    (y_true_oh + probs), axis=(2, 3)\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# calculate class totals\n",
    "single_intersect_sum = torch.sum(class_intersect,axis=0)\n",
    "single_denom_sum = torch.sum(class_denom,axis=0)\n",
    "\n",
    "multi_intersect_sum = torch.sum(torch.concat((class_intersect_0,class_intersect_1)),axis=0)\n",
    "multi_denom_sum = torch.sum(torch.concat((class_denom_0,class_denom_1)),axis=0)\n",
    "\n",
    "gather_intersect_sum_0 = torch.sum(class_intersect_gather_0,axis=0)\n",
    "gather_denom_sum_0 = torch.sum(class_denom_gather_0,axis=0)\n",
    "\n",
    "gather_intersect_sum_1 = torch.sum(class_intersect_gather_1,axis=0)\n",
    "gather_denom_sum_1 = torch.sum(class_denom_gather_1,axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "sanity_check: gather_0 should equal gather_1\n",
      "gather_intersect_sum_0 == gather_intersect_sum_1: 51 / 51 are equal\n",
      "gather_denom_sum_0 == gather_denom_sum_1: 51 / 51 are equal\n",
      "\n",
      "sanity_check: multi should equal gather_0 and gather_1\n",
      "multi_intersect_sum == gather_intersect_sum_0: 51 / 51 are equal\n",
      "multi_denom_sum == gather_denom_sum_0: 51 / 51 are equal\n",
      "\n",
      "Q: does single = gather?\n",
      "single_intersect_sum == gather_intersect_sum_0: 49 / 51 are equal\n",
      "single_denom_sum == gather_denom_sum_0: 34 / 51 are equal\n",
      "\n",
      "Q: does single = multi?\n",
      "single_intersect_sum == multi_intersect_sum: 49 / 51 are equal\n",
      "single_denom_sum == multi_denom_sum: 34 / 51 are equal\n"
     ]
    }
   ],
   "source": [
    "# comparing single_gpu and multi_gpu\n",
    "print('sanity_check: gather_0 should equal gather_1')\n",
    "nr_of_classes = len(single_intersect_sum)\n",
    "print(f'gather_intersect_sum_0 == gather_intersect_sum_1: {torch.sum(gather_intersect_sum_0 == gather_intersect_sum_1)} / {nr_of_classes} are equal')\n",
    "print(f'gather_denom_sum_0 == gather_denom_sum_1: {torch.sum(gather_denom_sum_0 == gather_denom_sum_1)} / {nr_of_classes} are equal')\n",
    "print()\n",
    "\n",
    "print('sanity_check: multi should equal gather_0 and gather_1')\n",
    "print(f'multi_intersect_sum == gather_intersect_sum_0: {torch.sum(multi_intersect_sum == gather_intersect_sum_0)} / {nr_of_classes} are equal')\n",
    "print(f'multi_denom_sum == gather_denom_sum_0: {torch.sum(multi_denom_sum == gather_denom_sum_0)} / {nr_of_classes} are equal')\n",
    "print()\n",
    "\n",
    "print('Q: does single = gather?')\n",
    "print(f'single_intersect_sum == gather_intersect_sum_0: {torch.sum(gather_intersect_sum_0 == single_intersect_sum)} / {nr_of_classes} are equal')\n",
    "print(f'single_denom_sum == gather_denom_sum_0: {torch.sum(gather_denom_sum_0 == single_denom_sum)} / {nr_of_classes} are equal')\n",
    "print()\n",
    "\n",
    "print('Q: does single = multi?')\n",
    "print(f'single_intersect_sum == multi_intersect_sum: {torch.sum(multi_intersect_sum == single_intersect_sum)} / {nr_of_classes} are equal')\n",
    "print(f'single_denom_sum == multi_denom_sum: {torch.sum(multi_denom_sum == single_denom_sum)} / {nr_of_classes} are equal')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
