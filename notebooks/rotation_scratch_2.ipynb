{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "import os\n",
    "import glob\n",
    "\n",
    "import numpy as np\n",
    "\n",
    "sys.path.append(\"../\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-04-11 16:59:28.487419: I tensorflow/core/util/port.cc:111] oneDNN custom operations are on. You may see slightly different numerical results due to floating-point round-off errors from different computation orders. To turn them off, set the environment variable `TF_ENABLE_ONEDNN_OPTS=0`.\n",
      "2024-04-11 16:59:28.558000: E tensorflow/compiler/xla/stream_executor/cuda/cuda_dnn.cc:9342] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
      "2024-04-11 16:59:28.558053: E tensorflow/compiler/xla/stream_executor/cuda/cuda_fft.cc:609] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
      "2024-04-11 16:59:28.558081: E tensorflow/compiler/xla/stream_executor/cuda/cuda_blas.cc:1518] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
      "2024-04-11 16:59:28.568797: I tensorflow/core/platform/cpu_feature_guard.cc:182] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: AVX2 AVX512F AVX512_VNNI FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2024-04-11 16:59:31.537329: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\n"
     ]
    }
   ],
   "source": [
    "from ext.lab2im import utils, edit_volumes\n",
    "import nobrainer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "SOURCE_DIR_00 = \"/om2/scratch/tmp/sabeen/kwyk_data/kwyk/rawdata/\"\n",
    "\n",
    "# TRANSFORM_DIR = '/om2/user/sabeen/kwyk_data/kwyk_transform_crop_1000'\n",
    "TRANSFORM_DIR = SOURCE_DIR_00\n",
    "FEATURE_TRANFORM_DIR = (\n",
    "    f\"{TRANSFORM_DIR}/features\" if TRANSFORM_DIR != SOURCE_DIR_00 else SOURCE_DIR_00\n",
    ")\n",
    "LABEL_TRANFORM_DIR = (\n",
    "    f\"{TRANSFORM_DIR}/labels\" if TRANSFORM_DIR != SOURCE_DIR_00 else SOURCE_DIR_00\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_feature_label_pairs(features_dir=SOURCE_DIR_00, labels_dir=SOURCE_DIR_00):\n",
    "    \"\"\"\n",
    "    Get pairs of feature and label filenames.\n",
    "    \"\"\"\n",
    "    features = sorted(glob.glob(os.path.join(features_dir, \"*orig*\")))[:10]\n",
    "    labels = sorted(glob.glob(os.path.join(labels_dir, \"*aseg*\")))[:10]\n",
    "\n",
    "    return list(zip(features, labels))\n",
    "\n",
    "feature_label_pairs = get_feature_label_pairs(FEATURE_TRANFORM_DIR,LABEL_TRANFORM_DIR)\n",
    "feature_files = [feature for feature, _ in feature_label_pairs]\n",
    "label_files = [label for _, label in feature_label_pairs]\n",
    "feature_files = sorted(feature_files)\n",
    "label_files = sorted(label_files)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "feature = feature_files[0]\n",
    "label = label_files[0]\n",
    "\n",
    "label_vol, label_aff, label_hdr = utils.load_volume(label, im_only=False)\n",
    "feature_vol, feature_aff, feature_hdr = utils.load_volume(feature, im_only=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "label_vol = label_vol.astype('int16')\n",
    "np.unique(label_vol)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "binary_label_vol = np.zeros(label_vol.shape)\n",
    "binary_label_vol[label_vol > 0] = 1\n",
    "np.unique(binary_label_vol)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "from nilearn import plotting\n",
    "import nibabel as nib\n",
    "from nobrainer.volume import standardize\n",
    "\n",
    "def load_brains(image_file: str, mask_file: str, file_path: str = ''):\n",
    "    # ensure that mask and image numbers match\n",
    "    image_nr = image_file.split(\"_\")[1]\n",
    "    mask_nr = mask_file.split(\"_\")[1]\n",
    "    assert image_nr == mask_nr, \"image and mask numbers do not match\"\n",
    "\n",
    "    if file_path != '':\n",
    "        image_path = os.path.join(file_path, image_file)\n",
    "        mask_path = os.path.join(file_path, mask_file)\n",
    "    else:\n",
    "        image_path = image_file\n",
    "        mask_path = mask_file\n",
    "\n",
    "    brain = nib.load(image_path)\n",
    "    brain_mask = nib.load(mask_path)\n",
    "\n",
    "    brain = brain.get_fdata()\n",
    "    brain_mask = brain_mask.get_fdata()\n",
    "    brain_mask = brain_mask.astype(int)\n",
    "    # apply skull stripping\n",
    "    brain[brain_mask == 0] = 0\n",
    "\n",
    "    return brain, brain_mask, image_nr\n",
    "\n",
    "def save_volume(volume, aff, header, path, res=None, dtype=None, n_dims=3):\n",
    "    \"\"\"\n",
    "    Save a volume.\n",
    "    :param volume: volume to save\n",
    "    :param aff: affine matrix of the volume to save. If aff is None, the volume is saved with an identity affine matrix.\n",
    "    aff can also be set to 'FS', in which case the volume is saved with the affine matrix of FreeSurfer outputs.\n",
    "    :param header: header of the volume to save. If None, the volume is saved with a blank header.\n",
    "    :param path: path where to save the volume.\n",
    "    :param res: (optional) update the resolution in the header before saving the volume.\n",
    "    :param dtype: (optional) numpy dtype for the saved volume.\n",
    "    :param n_dims: (optional) number of dimensions, to avoid confusion in multi-channel case. Default is None, where\n",
    "    n_dims is automatically inferred.\n",
    "    \"\"\"\n",
    "\n",
    "    # mkdir(os.path.dirname(path))\n",
    "    if \".npz\" in path:\n",
    "        np.savez_compressed(path, vol_data=volume)\n",
    "    else:\n",
    "        if header is None:\n",
    "            header = nib.Nifti1Header()\n",
    "        if isinstance(aff, str):\n",
    "            if aff == \"FS\":\n",
    "                aff = np.array(\n",
    "                    [[-1, 0, 0, 0], [0, 0, 1, 0], [0, -1, 0, 0], [0, 0, 0, 1]]\n",
    "                )\n",
    "        elif aff is None:\n",
    "            aff = np.eye(4)\n",
    "        if dtype is not None:\n",
    "            if \"int\" in dtype:\n",
    "                volume = np.round(volume)\n",
    "            volume = volume.astype(dtype=dtype)\n",
    "            nifty = nib.Nifti1Image(volume, aff, header)\n",
    "            nifty.set_data_dtype(dtype)\n",
    "        else:\n",
    "            nifty = nib.Nifti1Image(volume, aff, header)\n",
    "        # if res is not None:\n",
    "        #     if n_dims is None:\n",
    "        #         n_dims, _ = get_dims(volume.shape)\n",
    "        #     res = reformat_to_list(res, length=n_dims, dtype=None)\n",
    "        #     nifty.header.set_zooms(res)\n",
    "        nib.save(nifty, path)\n",
    "    return nifty, path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# feature_vol, label_vol, _ = load_brains(feature, label)\n",
    "\n",
    "# binary_label_vol = np.zeros(label_vol.shape)\n",
    "# binary_label_vol[label_vol > 0] == 1.0\n",
    "\n",
    "nifty, path = save_volume(binary_label_vol, None, None, '/om2/user/sabeen/tissue_labeling/misc/test_binary_label_vol_unrot')\n",
    "\n",
    "fig = plt.figure(figsize=(12, 6))\n",
    "plotting.plot_roi(\n",
    "    nifty,\n",
    "    bg_img='/om2/user/sabeen/tissue_labeling/misc/test_binary_label_vol_unrot.nii',\n",
    "    # cut_coords=(0, 10, -21),\n",
    "    alpha=0.4,\n",
    "    vmin=0,\n",
    "    vmax=5,\n",
    "    figure=fig,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def nobrainer_rotate(feature_vol, label_vol):\n",
    "    # randomly choose an angle between -20 to 20 for all axes\n",
    "    # angles = np.random.uniform(-20, 20, size=3)\n",
    "    angles = np.radians(np.array([20.0,20.0,20.0]))\n",
    "    print('angles', angles)\n",
    "    # assert feature_vol.shape == label_vol.shape\n",
    "\n",
    "    affine = nobrainer.transform.get_affine(feature_vol.shape, rotation=angles)\n",
    "    rotated_feature_vol = np.array(nobrainer.transform.warp(feature_vol, affine, order=1))\n",
    "    rotated_label_vol = np.array(\n",
    "        nobrainer.transform.warp(label_vol, affine, order=0)\n",
    "    ).astype(\"int16\")\n",
    "    return rotated_feature_vol, rotated_label_vol"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rotated_feature_vol, rotated_label_vol = nobrainer_rotate(feature_vol, label_vol)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "binary_label_vol_rot = np.zeros(rotated_label_vol.shape)\n",
    "binary_label_vol_rot[rotated_label_vol > 0] =  1\n",
    "np.unique(binary_label_vol_rot)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "nifty, path = save_volume(binary_label_vol_rot, None, None, '/om2/user/sabeen/tissue_labeling/misc/test_binary_label_vol_rot')\n",
    "\n",
    "fig = plt.figure(figsize=(12, 6))\n",
    "plotting.plot_roi(\n",
    "    nifty,\n",
    "    bg_img='/om2/user/sabeen/tissue_labeling/misc/test_binary_label_vol_rot.nii',\n",
    "    # cut_coords=(0, 10, -21),\n",
    "    alpha=0.4,\n",
    "    vmin=0,\n",
    "    vmax=5,\n",
    "    figure=fig,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from ext.lab2im import utils, edit_volumes\n",
    "\n",
    "def synthseg_rotation(feature_vol, label_vol):\n",
    "    angles = np.radians(np.array([20.0,20.0,20.0]))\n",
    "    affine = utils.create_affine_transformation_matrix(n_dims=3,rotation=angles)\n",
    "\n",
    "    rotated_feature_vol,_ = edit_volumes.resample_volume(feature_vol,affine,new_vox_size=[1,1,1],interpolation='linear',blur=False)\n",
    "    rotated_label_vol,_ = edit_volumes.resample_volume(label_vol,affine,new_vox_size=[1,1,1],interpolation='nearest',blur=False)\n",
    "    return rotated_feature_vol, rotated_label_vol"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "synthseg_rotated_feature_vol,synthseg_rotated_label_vol = synthseg_rotation(feature_vol,label_vol)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "binary_synthseg_rotated_label_vol = np.zeros(synthseg_rotated_label_vol.shape)\n",
    "binary_synthseg_rotated_label_vol[synthseg_rotated_label_vol > 0] = 1\n",
    "np.unique(binary_synthseg_rotated_label_vol)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "nifty, path = save_volume(binary_synthseg_rotated_label_vol, None, None, '/om2/user/sabeen/tissue_labeling/misc/test_binary_label_vol_rot_synth')\n",
    "\n",
    "fig = plt.figure(figsize=(12, 6))\n",
    "plotting.plot_roi(\n",
    "    nifty,\n",
    "    bg_img='/om2/user/sabeen/tissue_labeling/misc/test_binary_label_vol_rot_synth.nii',\n",
    "    # cut_coords=(0, 10, -21),\n",
    "    alpha=0.4,\n",
    "    vmin=0,\n",
    "    vmax=5,\n",
    "    figure=fig,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "(synthseg_rotated_label_vol == label_vol).all()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def nobrainer_get_coordinates(volume_shape):\n",
    "    \"\"\"Get coordinates that represent every voxel in a volume with shape\n",
    "    `volume_shape`.\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    volume_shape: tuple of length 3, shape of output volume.\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "    Tensor of coordinates with shape `(prod(volume_shape), 3)`.\n",
    "    \"\"\"\n",
    "    if len(volume_shape) < 3:\n",
    "        raise ValueError(\"shape must have at least 3 items.\")\n",
    "    dtype = tf.float32\n",
    "    rows, cols, depth = volume_shape[:3]\n",
    "\n",
    "    out = tf.meshgrid(\n",
    "        tf.range(rows, dtype=dtype),\n",
    "        tf.range(cols, dtype=dtype),\n",
    "        tf.range(depth, dtype=dtype),\n",
    "        indexing=\"ij\",\n",
    "    )\n",
    "    unreshaped = tf.stack(out, axis=3)\n",
    "    return tf.reshape(tf.stack(out, axis=3), shape=(-1, 3)), unreshaped\n",
    "\n",
    "def nobrainer_warp_coords(matrix, volume_shape):\n",
    "    \"\"\"Build the coordinates for a affine transform on volumetric data.\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    matrix: tensor with shape (4, 4), affine matrix.\n",
    "    volume_shape: tuple of length 3, shape of output volume.\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "    TODO check this.\n",
    "    Tensor of coordinates with shape (*volume_shape, 3).\n",
    "    \"\"\"\n",
    "    coords,_ = nobrainer_get_coordinates(volume_shape=volume_shape)\n",
    "    # Append ones to play nicely with 4x4 affine.\n",
    "    coords_homogeneous = tf.concat(\n",
    "        [coords, tf.ones((coords.shape[0], 1), dtype=coords.dtype)], axis=1\n",
    "    )\n",
    "    return (coords_homogeneous @ tf.transpose(matrix))[..., :3]\n",
    "\n",
    "def nobrainer_trilinear_interpolation(volume, coords):\n",
    "    \"\"\"Trilinear interpolation.\n",
    "\n",
    "    Implemented according to\n",
    "    https://en.wikipedia.org/wiki/Trilinear_interpolation#Method\n",
    "    https://github.com/Ryo-Ito/spatial_transformer_network/blob/2555e846b328e648a456f92d4c80fce2b111599e/warp.py#L137-L222\n",
    "    \"\"\"\n",
    "    volume = tf.cast(volume, tf.float32)\n",
    "    coords = tf.cast(coords, tf.float32)\n",
    "    coords_floor = tf.floor(coords)\n",
    "\n",
    "    shape = tf.shape(volume)\n",
    "    xlen = shape[0]\n",
    "    ylen = shape[1]\n",
    "    zlen = shape[2]\n",
    "\n",
    "    # Get lattice points. x0 is point below x, and x1 is point above x. Same for y and\n",
    "    # z.\n",
    "    x0 = tf.cast(coords_floor[:, 0], tf.int32)\n",
    "    x1 = x0 + 1\n",
    "    y0 = tf.cast(coords_floor[:, 1], tf.int32)\n",
    "    y1 = y0 + 1\n",
    "    z0 = tf.cast(coords_floor[:, 2], tf.int32)\n",
    "    z1 = z0 + 1\n",
    "\n",
    "    # Clip values to the size of the volume array.\n",
    "    x0 = tf.clip_by_value(x0, 0, xlen - 1)\n",
    "    x1 = tf.clip_by_value(x1, 0, xlen - 1)\n",
    "    y0 = tf.clip_by_value(y0, 0, ylen - 1)\n",
    "    y1 = tf.clip_by_value(y1, 0, ylen - 1)\n",
    "    z0 = tf.clip_by_value(z0, 0, zlen - 1)\n",
    "    z1 = tf.clip_by_value(z1, 0, zlen - 1)\n",
    "\n",
    "    # Get the indices at corners of cube.\n",
    "    i000 = x0 * ylen * zlen + y0 * zlen + z0\n",
    "    i001 = x0 * ylen * zlen + y0 * zlen + z1\n",
    "    i010 = x0 * ylen * zlen + y1 * zlen + z0\n",
    "    i011 = x0 * ylen * zlen + y1 * zlen + z1\n",
    "    i100 = x1 * ylen * zlen + y0 * zlen + z0\n",
    "    i101 = x1 * ylen * zlen + y0 * zlen + z1\n",
    "    i110 = x1 * ylen * zlen + y1 * zlen + z0\n",
    "    i111 = x1 * ylen * zlen + y1 * zlen + z1\n",
    "\n",
    "    # Get volume values at corners of cube.\n",
    "    if len(volume.shape) == 3:\n",
    "        volume_flat = tf.reshape(volume, [-1])\n",
    "    else:\n",
    "        volume_flat = tf.reshape(volume, [-1, volume.shape[-1]])\n",
    "\n",
    "    c000 = tf.gather(volume_flat, i000)\n",
    "    c001 = tf.gather(volume_flat, i001)\n",
    "    c010 = tf.gather(volume_flat, i010)\n",
    "    c011 = tf.gather(volume_flat, i011)\n",
    "    c100 = tf.gather(volume_flat, i100)\n",
    "    c101 = tf.gather(volume_flat, i101)\n",
    "    c110 = tf.gather(volume_flat, i110)\n",
    "    c111 = tf.gather(volume_flat, i111)\n",
    "\n",
    "    xd = coords[:, 0] - tf.cast(x0, tf.float32)\n",
    "    yd = coords[:, 1] - tf.cast(y0, tf.float32)\n",
    "    zd = coords[:, 2] - tf.cast(z0, tf.float32)\n",
    "\n",
    "    if len(volume.shape) == 4:\n",
    "        # Add a channels axis for proper broadcasting\n",
    "        xd = xd[:, tf.newaxis]\n",
    "        yd = yd[:, tf.newaxis]\n",
    "        zd = zd[:, tf.newaxis]\n",
    "\n",
    "    # Interpolate along x-axis.\n",
    "    c00 = c000 * (1 - xd) + c100 * xd\n",
    "    c01 = c001 * (1 - xd) + c101 * xd\n",
    "    c10 = c010 * (1 - xd) + c110 * xd\n",
    "    c11 = c011 * (1 - xd) + c111 * xd\n",
    "\n",
    "    # Interpolate along y-axis.\n",
    "    c0 = c00 * (1 - yd) + c10 * yd\n",
    "    c1 = c01 * (1 - yd) + c11 * yd\n",
    "\n",
    "    # Interpolate along z-axis.\n",
    "    c = c0 * (1 - zd) + c1 * zd\n",
    "\n",
    "    return tf.reshape(c, volume.shape)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-04-11 16:44:50.777824: E tensorflow/compiler/xla/stream_executor/cuda/cuda_driver.cc:268] failed call to cuInit: CUDA_ERROR_NO_DEVICE: no CUDA-capable device is detected\n",
      "2024-04-11 16:44:50.777874: I tensorflow/compiler/xla/stream_executor/cuda/cuda_diagnostics.cc:168] retrieving CUDA diagnostic information for host: node078\n",
      "2024-04-11 16:44:50.777882: I tensorflow/compiler/xla/stream_executor/cuda/cuda_diagnostics.cc:175] hostname: node078\n",
      "2024-04-11 16:44:50.778061: I tensorflow/compiler/xla/stream_executor/cuda/cuda_diagnostics.cc:199] libcuda reported version is: 550.54.14\n",
      "2024-04-11 16:44:50.778086: I tensorflow/compiler/xla/stream_executor/cuda/cuda_diagnostics.cc:203] kernel reported version is: 550.54.14\n",
      "2024-04-11 16:44:50.778092: I tensorflow/compiler/xla/stream_executor/cuda/cuda_diagnostics.cc:309] kernel version seems to match DSO: 550.54.14\n"
     ]
    }
   ],
   "source": [
    "vol_shape = (5,10,15)\n",
    "volume = np.random.rand(*vol_shape)\n",
    "affine = nobrainer.transform.get_affine(vol_shape, rotation=np.radians([20,20,20]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "nobrainer_coords, nobrainer_unreshaped = nobrainer_get_coordinates(vol_shape)\n",
    "nob_coords_homogeneous = tf.concat(\n",
    "        [nobrainer_coords, tf.ones((nobrainer_coords.shape[0], 1), dtype=nobrainer_coords.dtype)], axis=1\n",
    "    )\n",
    "print(nob_coords_homogeneous.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "nobrainer_warped_coords = nobrainer_warp_coords(affine,vol_shape)\n",
    "print(nobrainer_warped_coords.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "nobrainer_vol = nobrainer_trilinear_interpolation(volume, nobrainer_warped_coords)\n",
    "print(nobrainer_vol.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# MATCHES NOBRAINER RESULTS\n",
    "Nx, Ny, Nz = vol_shape\n",
    "x = np.linspace(0, Nx - 1, Nx)\n",
    "y = np.linspace(0, Ny - 1, Ny)\n",
    "z = np.linspace(0, Nz - 1, Nz)\n",
    "xx, yy, zz = np.meshgrid(x,y,z, indexing='ij')\n",
    "# coor = np.array([xx, yy, zz])\n",
    "coor = np.stack((xx,yy,zz),axis=3)\n",
    "coor_reshaped = np.reshape(coor,(-1,3))\n",
    "coor_homog = np.concatenate([coor_reshaped,np.ones((coor_reshaped.shape[0],1)).astype(coor_reshaped.dtype)], axis=1)\n",
    "warped_coords = (coor_homog @ np.transpose(affine))[..., :3]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "warped_coords[500], nobrainer_warped_coords[500]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def np_trilinear_interpolation(volume, coords): # MATCHES NOBRAINER RESULTS\n",
    "    \"\"\"Trilinear interpolation.\n",
    "\n",
    "    Implemented according to\n",
    "    https://en.wikipedia.org/wiki/Trilinear_interpolation#Method\n",
    "    https://github.com/Ryo-Ito/spatial_transformer_network/blob/2555e846b328e648a456f92d4c80fce2b111599e/warp.py#L137-L222\n",
    "    \"\"\"\n",
    "    volume = volume.astype(np.float32)\n",
    "    coords = warped_coords.astype(np.float32)\n",
    "    coords_floor = np.floor(coords)\n",
    "\n",
    "    shape = volume.shape\n",
    "    xlen = shape[0]\n",
    "    ylen = shape[1]\n",
    "    zlen = shape[2]\n",
    "\n",
    "    # Get lattice points. x0 is point below x, and x1 is point above x. Same for y and\n",
    "    # z.\n",
    "    x0 = coords_floor[:, 0].astype(np.int32)\n",
    "    x1 = x0 + 1\n",
    "    y0 = coords_floor[:, 1].astype(np.int32)\n",
    "    y1 = y0 + 1\n",
    "    z0 = coords_floor[:, 2].astype(np.int32)\n",
    "    z1 = z0 + 1\n",
    "\n",
    "    # Clip values to the size of the volume array.\n",
    "    x0 = np.clip(x0, 0, xlen - 1)\n",
    "    x1 = np.clip(x1, 0, xlen - 1)\n",
    "    y0 = np.clip(y0, 0, ylen - 1)\n",
    "    y1 = np.clip(y1, 0, ylen - 1)\n",
    "    z0 = np.clip(z0, 0, zlen - 1)\n",
    "    z1 = np.clip(z1, 0, zlen - 1)\n",
    "\n",
    "    i000 = x0 * ylen * zlen + y0 * zlen + z0\n",
    "    i001 = x0 * ylen * zlen + y0 * zlen + z1\n",
    "    i010 = x0 * ylen * zlen + y1 * zlen + z0\n",
    "    i011 = x0 * ylen * zlen + y1 * zlen + z1\n",
    "    i100 = x1 * ylen * zlen + y0 * zlen + z0\n",
    "    i101 = x1 * ylen * zlen + y0 * zlen + z1\n",
    "    i110 = x1 * ylen * zlen + y1 * zlen + z0\n",
    "    i111 = x1 * ylen * zlen + y1 * zlen + z1\n",
    "\n",
    "    if len(volume.shape) == 3:\n",
    "        volume_flat = np.reshape(volume, [-1])\n",
    "    else:\n",
    "        volume_flat = np.reshape(volume, [-1, volume.shape[-1]])\n",
    "\n",
    "    c000 = np.take(volume_flat, i000)\n",
    "    c001 = np.take(volume_flat, i001)\n",
    "    c010 = np.take(volume_flat, i010)\n",
    "    c011 = np.take(volume_flat, i011)\n",
    "    c100 = np.take(volume_flat, i100)\n",
    "    c101 = np.take(volume_flat, i101)\n",
    "    c110 = np.take(volume_flat, i110)\n",
    "    c111 = np.take(volume_flat, i111)\n",
    "\n",
    "    xd = coords[:, 0] - x0.astype(np.float32)\n",
    "    yd = coords[:, 1] - y0.astype(np.float32)\n",
    "    zd = coords[:, 2] - z0.astype(np.float32)\n",
    "\n",
    "    # Interpolate along x-axis.\n",
    "    c00 = c000 * (1 - xd) + c100 * xd\n",
    "    c01 = c001 * (1 - xd) + c101 * xd\n",
    "    c10 = c010 * (1 - xd) + c110 * xd\n",
    "    c11 = c011 * (1 - xd) + c111 * xd\n",
    "\n",
    "    # Interpolate along y-axis.\n",
    "    c0 = c00 * (1 - yd) + c10 * yd\n",
    "    c1 = c01 * (1 - yd) + c11 * yd\n",
    "\n",
    "    c = c0 * (1 - zd) + c1 * zd\n",
    "\n",
    "    return np.reshape(c, volume.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "volume = volume.astype(np.float32)\n",
    "coords = warped_coords.astype(np.float32)\n",
    "coords_floor = np.floor(coords)\n",
    "\n",
    "shape = volume.shape\n",
    "xlen = shape[0]\n",
    "ylen = shape[1]\n",
    "zlen = shape[2]\n",
    "\n",
    "# Get lattice points. x0 is point below x, and x1 is point above x. Same for y and\n",
    "# z.\n",
    "x0 = coords_floor[:, 0].astype(np.int32)\n",
    "x1 = x0 + 1\n",
    "y0 = coords_floor[:, 1].astype(np.int32)\n",
    "y1 = y0 + 1\n",
    "z0 = coords_floor[:, 2].astype(np.int32)\n",
    "z1 = z0 + 1\n",
    "\n",
    "# Clip values to the size of the volume array.\n",
    "x0 = np.clip(x0, 0, xlen - 1)\n",
    "x1 = np.clip(x1, 0, xlen - 1)\n",
    "y0 = np.clip(y0, 0, ylen - 1)\n",
    "y1 = np.clip(y1, 0, ylen - 1)\n",
    "z0 = np.clip(z0, 0, zlen - 1)\n",
    "z1 = np.clip(z1, 0, zlen - 1)\n",
    "\n",
    "i000 = x0 * ylen * zlen + y0 * zlen + z0\n",
    "i001 = x0 * ylen * zlen + y0 * zlen + z1\n",
    "i010 = x0 * ylen * zlen + y1 * zlen + z0\n",
    "i011 = x0 * ylen * zlen + y1 * zlen + z1\n",
    "i100 = x1 * ylen * zlen + y0 * zlen + z0\n",
    "i101 = x1 * ylen * zlen + y0 * zlen + z1\n",
    "i110 = x1 * ylen * zlen + y1 * zlen + z0\n",
    "i111 = x1 * ylen * zlen + y1 * zlen + z1\n",
    "\n",
    "if len(volume.shape) == 3:\n",
    "    volume_flat = np.reshape(volume, [-1])\n",
    "else:\n",
    "    volume_flat = np.reshape(volume, [-1, volume.shape[-1]])\n",
    "\n",
    "c000 = np.take(volume_flat, i000)\n",
    "c001 = np.take(volume_flat, i001)\n",
    "c010 = np.take(volume_flat, i010)\n",
    "c011 = np.take(volume_flat, i011)\n",
    "c100 = np.take(volume_flat, i100)\n",
    "c101 = np.take(volume_flat, i101)\n",
    "c110 = np.take(volume_flat, i110)\n",
    "c111 = np.take(volume_flat, i111)\n",
    "\n",
    "xd = coords[:, 0] - x0.astype(np.float32)\n",
    "yd = coords[:, 1] - y0.astype(np.float32)\n",
    "zd = coords[:, 2] - z0.astype(np.float32)\n",
    "\n",
    "# Interpolate along x-axis.\n",
    "c00 = c000 * (1 - xd) + c100 * xd\n",
    "c01 = c001 * (1 - xd) + c101 * xd\n",
    "c10 = c010 * (1 - xd) + c110 * xd\n",
    "c11 = c011 * (1 - xd) + c111 * xd\n",
    "\n",
    "# Interpolate along y-axis.\n",
    "c0 = c00 * (1 - yd) + c10 * yd\n",
    "c1 = c01 * (1 - yd) + c11 * yd\n",
    "\n",
    "c = c0 * (1 - zd) + c1 * zd\n",
    "\n",
    "interp = np.reshape(c, volume.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "interp = np_trilinear_interpolation(volume, warped_coords)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def nobrainer_get_voxels(volume, coords): # MATCHES NOBRAINER RESULTS\n",
    "    \"\"\"Get voxels from volume at points. These voxels are in a flat tensor.\"\"\"\n",
    "    x = tf.cast(volume, tf.float32)\n",
    "    coords = tf.cast(coords, tf.float32)\n",
    "\n",
    "    if len(x.shape) < 3:\n",
    "        raise ValueError(\"`volume` must be at least rank 3\")\n",
    "    if len(coords.shape) != 2 or coords.shape[1] != 3:\n",
    "        raise ValueError(\"`coords` must have shape `(N, 3)`.\")\n",
    "\n",
    "    rows, cols, depth, *n_channels = x.shape\n",
    "\n",
    "    # Points in flattened array representation.\n",
    "    fcoords = coords[:, 0] * cols * depth + coords[:, 1] * depth + coords[:, 2]\n",
    "\n",
    "    # Some computed finds are out of range of the image's flattened size.\n",
    "    # Zero those so we don't get errors. These points in the volume are filled later.\n",
    "    fcoords_size = tf.size(fcoords, out_type=fcoords.dtype)\n",
    "    fcoords = tf.clip_by_value(fcoords, 0, fcoords_size - 1)\n",
    "    xflat = tf.squeeze(tf.reshape(x, [tf.math.reduce_prod(x.shape[:3]), -1]))\n",
    "\n",
    "    # Reorder image data to transformed space.\n",
    "    xflat = tf.gather(params=xflat, indices=tf.cast(fcoords, tf.int32))\n",
    "\n",
    "    # Zero image data that was out of frame.\n",
    "    outofframe = (\n",
    "        tf.reduce_any(coords < 0, -1)\n",
    "        | (coords[:, 0] > rows)\n",
    "        | (coords[:, 1] > cols)\n",
    "        | (coords[:, 2] > depth)\n",
    "    )\n",
    "\n",
    "    if n_channels:\n",
    "        outofframe = tf.stack([outofframe for _ in range(n_channels[0])], axis=-1)\n",
    "\n",
    "    xflat = tf.multiply(xflat, tf.cast(tf.logical_not(outofframe), xflat.dtype))\n",
    "\n",
    "    return xflat"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "nobrainer_voxels = nobrainer_get_voxels(volume=volume, coords=tf.round(nobrainer_warped_coords))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def np_get_voxels(volume, coords):\n",
    "    \"\"\"Get voxels from volume at points. These voxels are in a flat tensor.\"\"\"\n",
    "    x = volume.astype(np.float32)\n",
    "    coords = coords.astype(np.float32)\n",
    "\n",
    "    if len(x.shape) < 3:\n",
    "        raise ValueError(\"`volume` must be at least rank 3\")\n",
    "    if len(coords.shape) != 2 or coords.shape[1] != 3:\n",
    "        raise ValueError(\"`coords` must have shape `(N, 3)`.\")\n",
    "\n",
    "    rows, cols, depth, *n_channels = x.shape\n",
    "\n",
    "    # Points in flattened array representation.\n",
    "    fcoords = coords[:, 0] * cols * depth + coords[:, 1] * depth + coords[:, 2]\n",
    "\n",
    "    # Some computed finds are out of range of the image's flattened size.\n",
    "    # Zero those so we don't get errors. These points in the volume are filled later.\n",
    "    fcoords_size = np.size(fcoords) * 1.0\n",
    "    fcoords = np.clip(fcoords, 0, fcoords_size - 1)\n",
    "    xflat = np.squeeze(np.reshape(x, [np.prod(x.shape[:3]), -1]))\n",
    "\n",
    "    # Reorder image data to transformed space.\n",
    "    xflat = np.take(xflat, indices=fcoords.astype(np.int32))\n",
    "\n",
    "    # Zero image data that was out of frame.\n",
    "    outofframe = (\n",
    "        np.any(coords < 0, -1)\n",
    "        | (coords[:, 0] > rows)\n",
    "        | (coords[:, 1] > cols)\n",
    "        | (coords[:, 2] > depth)\n",
    "    )\n",
    "\n",
    "    if n_channels:\n",
    "        outofframe = np.stack([outofframe for _ in range(n_channels[0])], axis=-1)\n",
    "\n",
    "    xflat = xflat * np.logical_not(outofframe).astype(xflat.dtype)\n",
    "\n",
    "    return xflat"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np_voxels = np_get_voxels(volume,np.round(warped_coords))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def nobrainer_nearest_neighbor_interpolation(volume, coords):\n",
    "    \"\"\"Three-dimensional nearest neighbors interpolation.\"\"\"\n",
    "    volume_f = nobrainer_get_voxels(volume=volume, coords=tf.round(coords))\n",
    "    return tf.reshape(volume_f, volume.shape)\n",
    "\n",
    "nobrainer_nearest = nobrainer_nearest_neighbor_interpolation(volume, nobrainer_warped_coords)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def np_nearest_neighbor_interpolation(volume, coords): #MATCHES NOBRAINER VERSION\n",
    "    \"\"\"Three-dimensional nearest neighbors interpolation.\"\"\"\n",
    "    volume_f = np_get_voxels(volume=volume, coords=np.round(coords))\n",
    "    return np.reshape(volume_f, volume.shape)\n",
    "\n",
    "np_nearest = np_nearest_neighbor_interpolation(volume, warped_coords)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "(np_nearest == np.array(nobrainer_nearest)).all()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "from TissueLabeling.brain_utils import np_warp_features_labels\n",
    "from nobrainer.transform import warp_features_labels as nob_warp_features_labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "nobrainer_feature, nobrainer_label = nob_warp_features_labels(volume,volume,affine)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "np_feature, np_label = np_warp_features_labels(volume, volume, affine)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.6768483 , 0.25291976, 0.30628937, 0.76994455, 0.8470567 ,\n",
       "        0.35417992, 0.29429865, 0.388851  , 0.2596641 , 0.13360512],\n",
       "       [0.52823603, 0.5099588 , 0.6822168 , 0.7956048 , 0.9229262 ,\n",
       "        0.45054898, 0.41697913, 0.25189778, 0.21098478, 0.16766718],\n",
       "       [0.33755022, 0.73677367, 0.8790368 , 0.56680334, 0.55487216,\n",
       "        0.56641364, 0.46990442, 0.3239779 , 0.22389337, 0.20172921],\n",
       "       [0.06480993, 0.35477626, 0.8948826 , 0.20037226, 0.2864908 ,\n",
       "        0.5252845 , 0.569538  , 0.30177903, 0.19813123, 0.22233976],\n",
       "       [0.4530878 , 0.50801575, 0.7702455 , 0.45247576, 0.64028263,\n",
       "        0.5992667 , 0.38509613, 0.41447946, 0.2223226 , 0.19657756]],\n",
       "      dtype=float32)"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np_feature[:,:,0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(5, 10), dtype=float32, numpy=\n",
       "array([[0.6768483 , 0.25291976, 0.30628937, 0.76994455, 0.8470567 ,\n",
       "        0.35417968, 0.29429883, 0.38885075, 0.2596641 , 0.13360512],\n",
       "       [0.52823603, 0.5099588 , 0.6822168 , 0.7956048 , 0.92292637,\n",
       "        0.45054898, 0.41697913, 0.25189784, 0.21098478, 0.16766718],\n",
       "       [0.33755022, 0.73677367, 0.8790367 , 0.56680334, 0.55487216,\n",
       "        0.56641364, 0.46990442, 0.3239779 , 0.22389337, 0.20172921],\n",
       "       [0.06480998, 0.35477632, 0.8948827 , 0.20037216, 0.28649077,\n",
       "        0.5252845 , 0.569538  , 0.30177897, 0.19813125, 0.22233976],\n",
       "       [0.4530878 , 0.5080158 , 0.7702453 , 0.45247588, 0.64028263,\n",
       "        0.5992667 , 0.38509613, 0.4144795 , 0.2223226 , 0.19657758]],\n",
       "      dtype=float32)>"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nobrainer_feature[:,:,0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 0.8830222 , -0.21147065,  0.41898912, -1.7473502 ],\n",
       "       [ 0.3213938 ,  0.9230309 , -0.21147065,  1.1838677 ],\n",
       "       [-0.34202012,  0.3213938 ,  0.8830222 ,  0.05661297],\n",
       "       [ 0.        ,  0.        ,  0.        ,  1.        ]],\n",
       "      dtype=float32)"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vol_shape = (5,10,15)\n",
    "affine2 = np_get_affine(vol_shape, rotation=np.radians([20,20,20]))\n",
    "affine2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(4, 4), dtype=float32, numpy=\n",
       "array([[ 0.8830222 , -0.21147065,  0.41898912, -1.7473502 ],\n",
       "       [ 0.3213938 ,  0.9230309 , -0.21147065,  1.1838677 ],\n",
       "       [-0.34202012,  0.3213938 ,  0.8830222 ,  0.05661297],\n",
       "       [ 0.        ,  0.        ,  0.        ,  1.        ]],\n",
       "      dtype=float32)>"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "affine = nob_get_affine(vol_shape, rotation=np.radians([20,20,20]))\n",
    "affine"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def nob_get_affine(volume_shape, rotation=[0, 0, 0], translation=[0, 0, 0]):\n",
    "    \"\"\"Return 4x4 affine, which encodes rotation and translation of 3D tensors.\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    rotation: iterable of three numbers, the yaw, pitch, and roll,\n",
    "        respectively, in radians.\n",
    "    translation: iterable of three numbers, the number of voxels to translate\n",
    "        in the x, y, and z directions.\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "    Tensor with shape `(4, 4)` and dtype float32.\n",
    "    \"\"\"\n",
    "    volume_shape = tf.cast(volume_shape, tf.float32)\n",
    "    rotation = tf.cast(rotation, tf.float32)\n",
    "    translation = tf.cast(translation, tf.float32)\n",
    "    if volume_shape.shape[0] < 3:\n",
    "        raise ValueError(\"`volume_shape` must have at least three values\")\n",
    "    if rotation.shape[0] != 3:\n",
    "        raise ValueError(\"`rotation` must have three values\")\n",
    "    if translation.shape[0] != 3:\n",
    "        raise ValueError(\"`translation` must have three values\")\n",
    "\n",
    "    # ROTATION\n",
    "    # yaw\n",
    "    rx = tf.convert_to_tensor(\n",
    "        [\n",
    "            [1, 0, 0, 0],\n",
    "            [0, tf.math.cos(rotation[0]), -tf.math.sin(rotation[0]), 0],\n",
    "            [0, tf.math.sin(rotation[0]), tf.math.cos(rotation[0]), 0],\n",
    "            [0, 0, 0, 1],\n",
    "        ],\n",
    "        dtype=tf.float32,\n",
    "    )\n",
    "\n",
    "    # pitch\n",
    "    ry = tf.convert_to_tensor(\n",
    "        [\n",
    "            [tf.math.cos(rotation[1]), 0, tf.math.sin(rotation[1]), 0],\n",
    "            [0, 1, 0, 0],\n",
    "            [-tf.math.sin(rotation[1]), 0, tf.math.cos(rotation[1]), 0],\n",
    "            [0, 0, 0, 1],\n",
    "        ],\n",
    "        dtype=tf.float32,\n",
    "    )\n",
    "\n",
    "    # roll\n",
    "    rz = tf.convert_to_tensor(\n",
    "        [\n",
    "            [tf.math.cos(rotation[2]), -tf.math.sin(rotation[2]), 0, 0],\n",
    "            [tf.math.sin(rotation[2]), tf.math.cos(rotation[2]), 0, 0],\n",
    "            [0, 0, 1, 0],\n",
    "            [0, 0, 0, 1],\n",
    "        ],\n",
    "        dtype=tf.float32,\n",
    "    )\n",
    "\n",
    "    # Rotation around origin.\n",
    "    transform = rz @ ry @ rx\n",
    "\n",
    "    center = tf.convert_to_tensor(volume_shape[:3] / 2 - 0.5, dtype=tf.float32)\n",
    "    neg_center = tf.math.negative(center)\n",
    "    center_to_origin = tf.convert_to_tensor(\n",
    "        [\n",
    "            [1, 0, 0, neg_center[0]],\n",
    "            [0, 1, 0, neg_center[1]],\n",
    "            [0, 0, 1, neg_center[2]],\n",
    "            [0, 0, 0, 1],\n",
    "        ],\n",
    "        dtype=tf.float32,\n",
    "    )\n",
    "\n",
    "    origin_to_center = tf.convert_to_tensor(\n",
    "        [\n",
    "            [1, 0, 0, center[0]],\n",
    "            [0, 1, 0, center[1]],\n",
    "            [0, 0, 1, center[2]],\n",
    "            [0, 0, 0, 1],\n",
    "        ],\n",
    "        dtype=tf.float32,\n",
    "    )\n",
    "\n",
    "    # Rotation around center of volume.\n",
    "    transform = origin_to_center @ transform @ center_to_origin\n",
    "\n",
    "    # TRANSLATION\n",
    "    translation = tf.convert_to_tensor(\n",
    "        [\n",
    "            [1, 0, 0, translation[0]],\n",
    "            [0, 1, 0, translation[1]],\n",
    "            [0, 0, 1, translation[2]],\n",
    "            [0, 0, 0, 1],\n",
    "        ],\n",
    "        dtype=tf.float32,\n",
    "    )\n",
    "\n",
    "    transform = translation @ transform\n",
    "\n",
    "    # REFLECTION\n",
    "    #\n",
    "    # TODO.\n",
    "    # See http://web.iitd.ac.in/~hegde/cad/lecture/L6_3dtrans.pdf#page=7\n",
    "    # and https://en.wikipedia.org/wiki/Transformation_matrix#Reflection_2\n",
    "\n",
    "    return transform"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "def np_get_affine(volume_shape, rotation=[0, 0, 0], translation=[0, 0, 0]): # MATCHES NOBRAINER OUTPUT\n",
    "    \"\"\"Return 4x4 affine, which encodes rotation and translation of 3D tensors.\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    rotation: iterable of three numbers, the yaw, pitch, and roll,\n",
    "        respectively, in radians.\n",
    "    translation: iterable of three numbers, the number of voxels to translate\n",
    "        in the x, y, and z directions.\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "    Tensor with shape `(4, 4)` and dtype float32.\n",
    "    \"\"\"\n",
    "    volume_shape = np.array(volume_shape).astype(np.float32)\n",
    "    rotation = np.array(rotation).astype(np.float32)\n",
    "    translation = np.array(translation).astype(np.float32)\n",
    "    if volume_shape.shape[0] < 3:\n",
    "        raise ValueError(\"`volume_shape` must have at least three values\")\n",
    "    if rotation.shape[0] != 3:\n",
    "        raise ValueError(\"`rotation` must have three values\")\n",
    "    if translation.shape[0] != 3:\n",
    "        raise ValueError(\"`translation` must have three values\")\n",
    "\n",
    "    # ROTATION\n",
    "    # yaw\n",
    "    rx = np.array(\n",
    "        [\n",
    "            [1, 0, 0, 0],\n",
    "            [0, np.cos(rotation[0]), -np.sin(rotation[0]), 0],\n",
    "            [0, np.sin(rotation[0]), np.cos(rotation[0]), 0],\n",
    "            [0, 0, 0, 1],\n",
    "        ],\n",
    "        dtype=np.float32\n",
    "    )\n",
    "\n",
    "    # pitch\n",
    "    ry = np.array(\n",
    "        [\n",
    "            [np.cos(rotation[1]), 0, np.sin(rotation[1]), 0],\n",
    "            [0, 1, 0, 0],\n",
    "            [-np.sin(rotation[1]), 0, np.cos(rotation[1]), 0],\n",
    "            [0, 0, 0, 1],\n",
    "        ],\n",
    "        dtype=np.float32\n",
    "    )\n",
    "\n",
    "    # roll\n",
    "    rz = np.array(\n",
    "        [\n",
    "            [np.cos(rotation[2]), -np.sin(rotation[2]), 0, 0],\n",
    "            [np.sin(rotation[2]), np.cos(rotation[2]), 0, 0],\n",
    "            [0, 0, 1, 0],\n",
    "            [0, 0, 0, 1],\n",
    "        ],\n",
    "        dtype=np.float32\n",
    "    )\n",
    "\n",
    "    # Rotation around origin.\n",
    "    transform = rz @ ry @ rx\n",
    "\n",
    "    center = (volume_shape[:3] / 2 - 0.5).astype(np.float32)\n",
    "    neg_center = -1 * center\n",
    "    center_to_origin = np.array(\n",
    "        [\n",
    "            [1, 0, 0, neg_center[0]],\n",
    "            [0, 1, 0, neg_center[1]],\n",
    "            [0, 0, 1, neg_center[2]],\n",
    "            [0, 0, 0, 1],\n",
    "        ],\n",
    "        dtype=np.float32,\n",
    "    )\n",
    "\n",
    "    origin_to_center = np.array(\n",
    "        [\n",
    "            [1, 0, 0, center[0]],\n",
    "            [0, 1, 0, center[1]],\n",
    "            [0, 0, 1, center[2]],\n",
    "            [0, 0, 0, 1],\n",
    "        ],\n",
    "        dtype=np.float32,\n",
    "    )\n",
    "\n",
    "    # Rotation around center of volume.\n",
    "    transform = origin_to_center @ transform @ center_to_origin\n",
    "\n",
    "    # TRANSLATION\n",
    "    translation = np.array(\n",
    "        [\n",
    "            [1, 0, 0, translation[0]],\n",
    "            [0, 1, 0, translation[1]],\n",
    "            [0, 0, 1, translation[2]],\n",
    "            [0, 0, 0, 1],\n",
    "        ],\n",
    "        dtype=np.float32,\n",
    "    )\n",
    "\n",
    "    transform = translation @ transform\n",
    "\n",
    "    # REFLECTION\n",
    "    #\n",
    "    # TODO.\n",
    "    # See http://web.iitd.ac.in/~hegde/cad/lecture/L6_3dtrans.pdf#page=7\n",
    "    # and https://en.wikipedia.org/wiki/Transformation_matrix#Reflection_2\n",
    "\n",
    "    return transform"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "tissue_labeling",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
